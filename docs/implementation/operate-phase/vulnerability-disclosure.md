---
title: "Vulnerability Disclosure (CVD)"
sidebar_label: "Vulnerability Disclosure"
tags: [cvd, vulnerability-disclosure, cra, enisa, security-txt]
---
# Guide: Coordinated Vulnerability Disclosure

**Coordinated Vulnerability Disclosure (CVD)** is the process through which security researchers and the public can report potential vulnerabilities to a product manufacturer, allowing the manufacturer time to remediate the issue before the vulnerability is publicly disclosed. It is a collaborative approach that is a cornerstone of modern cybersecurity.

Under the **Cyber-Resilience Act (CRA)**, having a public CVD policy is a legal requirement ([CRA Annex I.II.5][cra_annexI_partII]). Manufacturers must provide a clear and accessible channel for third parties to report security issues. The CRA also introduces strict new reporting obligations to government bodies for actively exploited vulnerabilities.

## 1. Key Components of a CVD Policy

Your public CVD policy is a promise to the security community. It should be easy to find and understand. A best practice is to place it in a `security.txt` file in the `.well-known` directory of your main company website. This file should point to a dedicated web page that details your policy.

Your policy must include:
-   **The Promise:** A statement that you value the work of security researchers and will not take legal action against them for good-faith research that complies with your policy. This is often called a "Safe Harbor" statement.
-   **The Scope:** A clear definition of which products, services, and software versions are covered by the policy. It should also define what types of testing are not permitted (e.g., denial-of-service attacks).
-   **Reporting Channels:** One or more secure ways for researchers to contact you. This is typically a dedicated email address (e.g., `security@example.com`) and/or a web form.
-   **Response Timelines:** Service Level Agreements (SLAs) for how quickly you will respond. For example:
    -   Acknowledge receipt of a report within **2 business days**.
    -   Provide an initial assessment of the report within **10 business days**.
    -   Provide regular updates on the status of remediation.

## 2. The Internal Triage Workflow

Once you receive a vulnerability report, a structured internal process is essential.

| Step | Action | Key Activities |
| :--- | :--- | :--- |
| **1. Intake** | Acknowledge receipt of the report to the researcher. Create an internal ticket to track the issue. | Log the report, confirm you have all necessary information. |
| **2. Triage** | Validate that the vulnerability is real and affects a product in scope. Assign a severity score (e.g., using CVSS). | Reproduce the issue, determine the impact, prioritize based on severity. |
| **3. Remediation** | The engineering team develops, tests, and deploys a patch. | Develop the fix, perform QA, schedule the release according to your [patch cadence policy](./patch-cadence.md). |
| **4. Disclosure** | Once the patch is available, coordinate the public disclosure with the researcher. This may involve publishing a security advisory and requesting a CVE identifier. | Announce the fix, credit the researcher (with their permission). |

## 3. Mandatory ENISA Reporting (CRA Art. 14)

The CRA introduces a significant new reporting requirement. From **11 September 2026**, manufacturers have a legal duty to notify the EU's cybersecurity agency, **ENISA**, of any **actively exploited** vulnerability in their products.

-   **Initial Notification:** An "early warning" must be sent to ENISA within **24 hours** of becoming aware of the active exploitation.
-   **Mitigation Report:** Within **14 days**, the manufacturer must provide a report detailing the vulnerability, its impact, and any mitigation measures applied.
-   **Final Report:** A final report must be submitted after the vulnerability has been remediated.

This 24-hour deadline requires a well-drilled incident response process.

## 4. Compliance Checklist

- [ ] **Public CVD Policy:** Do you have a clear, public CVD policy?
- [ ] **`security.txt`:** Have you created a `security.txt` file on your website to direct researchers to your policy?
- [ ] **Secure Reporting Channel:** Do you have a monitored, secure channel for receiving vulnerability reports?
- [ ] **Internal Triage Process:** Is your internal workflow for handling reports documented and understood by your team?
- [ ] **ENISA Reporting Plan:** Do you have a specific incident response plan to meet the 24-hour ENISA reporting deadline for actively exploited vulnerabilities?
- [ ] **Documentation:** Is your CVD policy and internal process documented in your technical file?

---

*This content is being developed. Contribute to this page via our [GitHub repository](https://github.com/sbd-community/handbook).*

<!-- Shared links -->
[cra_art14]: ../../standards/cra-overview.md#core-manufacturer-obligations "CRA Article 14 – Reporting obligations of manufacturers"
[cra_annexI_partII]: ../../standards/cra-overview.md#annex-i-benchmarks "CRA Annex I, Part II – Vulnerability handling requirements"
[cra_annexI]: ../../standards/cra-overview.md#annex-i-benchmarks "CRA Annex I – Essential cybersecurity requirements" 