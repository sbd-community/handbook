---
title: "Vulnerability Disclosure (CVD)"
sidebar_label: "Vulnerability Disclosure"
tags: [cvd, vulnerability-disclosure, cra, enisa, security-txt]
sidebar_position: 1
---
# Guide: Coordinated Vulnerability Disclosure

## 1. Introduction to Coordinated Vulnerability Disclosure

### 1.1. What is Coordinated Vulnerability Disclosure (CVD)?

**Coordinated Vulnerability Disclosure (CVD)** is the process through which security researchers and the public can report potential vulnerabilities to a product manufacturer, allowing the manufacturer time to remediate the issue before it is publicly disclosed. It is a collaborative approach that is a cornerstone of modern cybersecurity and a mandatory legal requirement.

### 1.2. The Regulatory Requirement

The **[Cyber-Resilience Act (CRA)](./../../standards/eu/cra-overview.md)** elevates CVD from a best practice to a legal obligation:

-   **Vulnerability Disclosure Policy ([Annex I, Part II, § 5][cra_annexI])**: The CRA requires manufacturers to "put in place and enforce a policy on coordinated vulnerability disclosure."
-   The BSI TR-03183-1 provides the details, requiring a public document that defines a reporting process and contact channels ([REQ_VH 5][bsi_tr_03183_p1]).

Beyond this, the CRA also introduces strict new reporting obligations to government bodies for actively exploited vulnerabilities, making a well-practiced internal triage process essential.

### 1.3. Do I Really Need to Do This?

**Yes. Having a public vulnerability disclosure policy is a non-negotiable legal requirement and the bedrock of a healthy relationship with the security community.**

-   **It's a Legal Mandate:** The **[Cyber-Resilience Act (CRA)](../../standards/eu/cra-overview.md)** explicitly requires manufacturers to "put in place and enforce a policy on coordinated vulnerability disclosure." The UK's **PSTI Act** has similar requirements. This is a baseline for market access.
-   **It Prevents Chaotic Disclosure:** If security researchers can't find a way to contact you, they are more likely to disclose the vulnerability publicly (e.g., on social media). A clear, easy-to-find CVD policy gives them a constructive path to report issues, giving you time to fix them before they become a public crisis.
-   **It's Free Security Help:** Security researchers who report vulnerabilities to you are essentially providing free testing and analysis. Embracing the community and making it easy for them to report issues is one of the most cost-effective ways to improve your product's security.
-   **It's Required for Incident Response:** The CRA's 24-hour reporting deadline to ENISA for actively exploited vulnerabilities is extremely tight. A well-practiced internal triage process, which is a core part of CVD, is essential to be able to meet this deadline.

A CVD policy is not about admitting your product has flaws; it's about demonstrating you have a mature, professional process for dealing with them when they are inevitably discovered. It is a sign of strength, not weakness.

## 2. Key Components of a CVD Policy

Your public CVD policy is a promise to the security community. It should be easy to find and understand. A best practice is to place it in a `security.txt` file in the `.well-known` directory of your main company website. This file should point to a dedicated web page that details your policy.

Your policy must include:
-   **The Promise:** A statement that you value the work of security researchers and will not take legal action against them for good-faith research that complies with your policy. This is often called a "Safe Harbor" statement.
-   **The Scope:** A clear definition of which products, services, and software versions are covered by the policy. It should also define what types of testing are not permitted (e.g., denial-of-service attacks).
-   **Reporting Channels:** One or more secure ways for researchers to contact you. This is typically a dedicated email address (e.g., `security@example.com`) and/or a web form.
-   **Response Timelines:** Service Level Agreements (SLAs) for how quickly you will respond. For example:
    -   Acknowledge receipt of a report within **2 business days**.
    -   Provide an initial assessment of the report within **10 business days**.
    -   Provide regular updates on the status of remediation.

## 3. The Internal Triage Workflow

Once you receive a vulnerability report, a structured internal process is essential.

| Step | Action | Key Activities |
| :--- | :--- | :--- |
| **1. Intake** | Acknowledge receipt of the report to the researcher. Create an internal ticket to track the issue. | Log the report, confirm you have all necessary information. |
| **2. Triage** | Validate that the vulnerability is real and affects a product in scope. Assign a severity score (e.g., using CVSS). | Reproduce the issue, determine the impact, prioritize based on severity. |
| **3. Remediation** | The engineering team develops, tests, and deploys a patch. | Develop the fix, perform QA, schedule the release according to your [patch cadence policy](./patch-cadence.md). |
| **4. Disclosure** | Once the patch is available, coordinate the public disclosure with the researcher. This may involve publishing a security advisory and requesting a CVE identifier. | Announce the fix, credit the researcher (with their permission). |

## 4. Mandatory ENISA Reporting (CRA Art. 14)

The CRA introduces a significant new reporting requirement. From **11 September 2026**, manufacturers have a legal duty to notify the EU's cybersecurity agency, **ENISA**, of any **actively exploited** vulnerability in their products.

-   **Initial Notification:** An "early warning" must be sent to ENISA within **24 hours** of becoming aware of the active exploitation.
-   **Mitigation Report:** Within **14 days**, the manufacturer must provide a report detailing the vulnerability, its impact, and any mitigation measures applied.
-   **Final Report:** A final report must be submitted after the vulnerability has been remediated.

This 24-hour deadline requires a well-drilled incident response process.

## 5. Compliance Checklist

- [ ] **Public CVD Policy:** Do you have a clear, public CVD policy?
- [ ] **`security.txt`:** Have you created a `security.txt` file on your website to direct researchers to your policy?
- [ ] **Secure Reporting Channel:** Do you have a monitored, secure channel for receiving vulnerability reports?
- [ ] **Internal Triage Process:** Is your internal workflow for handling reports documented and understood by your team?
- [ ] **ENISA Reporting Plan:** Do you have a specific incident response plan to meet the 24-hour ENISA reporting deadline for actively exploited vulnerabilities?
- [ ] **Documentation:** Is your CVD policy and internal process documented in your technical file?

<!-- Citations -->
[cra_art14]: https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX:02024R2847-20241120#art_14 "CRA Article 14 – Reporting obligations of manufacturers"
[cra_annexI]: https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX:02024R2847-20241120#anx_I "CRA Annex I – Essential cybersecurity requirements"
[bsi_tr_03183_p1]: https://www.bsi.bund.de/SharedDocs/Downloads/EN/BSI/Publications/TechGuidelines/TR03183/BSI-TR-03183-1-0_9_0.pdf "BSI TR-03183 Part 1: General requirements"